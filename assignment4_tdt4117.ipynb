{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "298d865a",
   "metadata": {},
   "source": [
    "\n",
    "# Assignment 4: Embedding Models, Dense Retrieval, and RAG\n",
    "\n",
    "**Student names**: Vegard Aa Albretsen <br>\n",
    "**Group number**: 62 <br>\n",
    "**Date**: _We will see_\n",
    "\n",
    "## Important notes\n",
    "Please carefully read the following notes and consider them for the assignment delivery. Submissions that do not fulfill these requirements will not be assessed and should be submitted again.\n",
    "1. You may work in groups of maximum 2 students.\n",
    "2. The assignment must be delivered in ipynb format.\n",
    "3. The assignment must be typed. Handwritten assignments are not accepted.\n",
    "\n",
    "**Due date**: 26.10.2025 23:59\n",
    "\n",
    "In this assignment, you will:\n",
    "- Build a vector search index over a blog corpus using sentence embeddings\n",
    "- Implement dense retrieval (cosine similarity)\n",
    "- Use the vector index as the foundation for a simple Retrieval-Augmented Generation (RAG) chat system with evaluation on three queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf612534",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Dataset\n",
    "\n",
    "You will use the blog files, provided in the folder: \n",
    "- `blogs-sample` (in the same directory as this notebook)\n",
    "\n",
    "Use only the blog files provided in the folder below. Each file contains multiple `<post>` elements. Treat **each `<post>` as a separate document**.\n",
    "\n",
    "**The code to parse files is not provided. Implement the loading yourself in 4.1.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d681c2",
   "metadata": {},
   "source": [
    "\n",
    "## 4.1 – Load and parse blog documents\n",
    "\n",
    "Load all XML files from `blogs-sample`, extract the text of each `<post>`, and store one string per document. Keep the raw text per post as the document text.\n",
    "\n",
    "You may experience some trouble parsing all lines in the files, but this is okay.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "389dfee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 XML files under C:\\Users\\vegar\\OneDrive - NTNU\\Skule\\Fag\\Informasjonsgjenfinning\\TDT4117Assignment4\\blogs-sample\n",
      "11253.male.26.Technology.Aquarius.xml: 7 <post> tags\n",
      "11762.female.25.Student.Aries.xml: 20 <post> tags\n",
      "15365.female.34.indUnk.Cancer.xml: 844 <post> tags\n",
      "17944.female.39.indUnk.Sagittarius.xml: 128 <post> tags\n",
      "21828.male.40.Internet.Cancer.xml: 69 <post> tags\n",
      "23166.female.25.indUnk.Virgo.xml: 1 <post> tags\n",
      "23191.female.23.Advertising.Taurus.xml: 5 <post> tags\n",
      "23676.male.33.Technology.Scorpio.xml: 12 <post> tags\n",
      "24336.male.24.Technology.Leo.xml: 849 <post> tags\n",
      "26357.male.27.indUnk.Leo.xml: 41 <post> tags\n",
      "27603.male.24.Advertising.Sagittarius.xml: 52 <post> tags\n",
      "28417.female.24.Arts.Capricorn.xml: 73 <post> tags\n",
      "28451.male.27.Internet.Aquarius.xml: 13 <post> tags\n",
      "40964.female.23.RealEstate.Leo.xml: 5 <post> tags\n",
      "46465.male.25.Internet.Virgo.xml: 19 <post> tags\n",
      "47519.male.23.Communications-Media.Sagittarius.xml: 179 <post> tags\n",
      "48428.female.34.indUnk.Aquarius.xml: 5 <post> tags\n",
      "48923.female.23.Student.Virgo.xml: 128 <post> tags\n",
      "49663.male.33.indUnk.Taurus.xml: 1252 <post> tags\n",
      "61176.male.33.Technology.Capricorn.xml: 3 <post> tags\n",
      "7596.male.26.Internet.Scorpio.xml: 14 <post> tags\n",
      "8173.male.42.indUnk.Capricorn.xml: 1007 <post> tags\n",
      "8349.male.24.Consulting.Cancer.xml: 70 <post> tags\n",
      "9289.male.23.Marketing.Taurus.xml: 89 <post> tags\n",
      "9470.male.25.Communications-Media.Aries.xml: 360 <post> tags\n",
      "Total posts: 5245\n",
      "11253.male.26.Technology.Aquarius.xml#1 => About to go t bed late (again) got sucked into (another) late night film. Tonight was  urlLink Maybe Baby . It was reall\n",
      "11253.male.26.Technology.Aquarius.xml#2 => My Dad has always wanted to go to  urlLink America . I have been several times, for holidays, to see friends or for work\n",
      "11253.male.26.Technology.Aquarius.xml#3 => ...is a guy painting a blue wall blue.\n",
      "11253.male.26.Technology.Aquarius.xml#4 => Can't the  urlLink weather  just sort itself out. I'm sure we'd already had 2 heat waves by this point last year. I look\n",
      "11253.male.26.Technology.Aquarius.xml#5 => At last back to a normal company where it expected that you go to the pub at lunch on Fridays. Plus they have free break\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "folder = Path(\"blogs-sample\").resolve()\n",
    "assert folder.is_dir(), f\"Folder not found: {folder}\"\n",
    "\n",
    "documents = {}\n",
    "files = [p for p in folder.rglob(\"*.xml\")]\n",
    "\n",
    "print(f\"Found {len(files)} XML files under {folder}\")\n",
    "\n",
    "for f in files:\n",
    "    data = f.read_bytes()\n",
    "    soup = BeautifulSoup(data, \"xml\")\n",
    "\n",
    "    # strip namespace prefixes like ns:post -> post\n",
    "    for t in soup.find_all(True):\n",
    "        if \":\" in t.name:\n",
    "            t.name = t.name.split(\":\", 1)[1]\n",
    "\n",
    "    # posts directly anywhere under Blog/date/post/date/post...\n",
    "    posts = soup.find_all(\"post\")\n",
    "    print(f\"{f.name}: {len(posts)} <post> tags\")\n",
    "\n",
    "    for i, p in enumerate(posts, 1):\n",
    "        documents[f\"{f.name}#{i}\"] = p.get_text(strip=True)\n",
    "\n",
    "print(f\"Total posts: {len(documents)}\")\n",
    "# show a few\n",
    "for k, v in list(documents.items())[:5]:\n",
    "    print(k, \"=>\", v[:120])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eda412",
   "metadata": {},
   "source": [
    "\n",
    "## 4.2 – Embedding Models\n",
    "\n",
    "Select and load a sentence embedding model (e.g., `sentence-transformers/all-MiniLM-L6-v2`) and compute embeddings for all documents.\n",
    "\n",
    "- Store document embeddings in a variable named `doc_embeddings`.\n",
    "- Ensure that the same model will be used for query encoding later.\n",
    "\n",
    "**Report**:\n",
    "- The embedding matrix shape \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146a6c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (5245, 384)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: Load a sentence embedding model and encode all documents into `doc_embeddings`.\n",
    "# You may use `sentence-transformers`. Report the embedding matrix shape.\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# documents: dict[str, str]\n",
    "ids, texts = zip(*documents.items())  # stable order\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# 384-dim embeddings; normalize for cosine\n",
    "doc_embeddings = model.encode(\n",
    "    list(texts),\n",
    "    batch_size=128,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True,\n",
    ").astype(\"float32\")\n",
    "\n",
    "print(\"Embedding matrix shape:\", doc_embeddings.shape)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6defe752",
   "metadata": {},
   "source": [
    "\n",
    "## 4.3 – Dense Retrieval\n",
    "\n",
    "Implement a cosine similarity search over `doc_embeddings` for a given query.\n",
    "\n",
    "- Write a function `dense_search(query: str, k: int = 5) -> list[int]` that returns the indices of the top-k documents.\n",
    "- Use the same embedding model to encode the query.\n",
    "- Use cosine similarity for ranking.\n",
    "\n",
    "**Report**:\n",
    "- Results for the provided query showing the indices of the top results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e35dd7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urlLink Workplace : \"For INFPs the job search can be an opportunity to use their creativity, flexibility and their skills in self-expression. They can generate a variety of job possibilities, consider them for their ability to fulfill their values, and pursue them using their skills in communicating with others, either in writing or in person. Their idealism, commitment, flexibility and people skills will usually be communicated to others in the job search. Potential drawbacks for INFPs in the job search include unrealistic expectations for a job, feelings of inadequacy or lack of confidence, and inattention to details of the jobs or of the job search. Under stress, INFPs may become quite critical of others and themselves, and they may hold themselves back because they feel incompetent as they engage in this process. They can benefit from allowing their intuition to give them a new perspective on the possibilities available in the situation. They may also find it helpful to truly acknowledge their skills, as well as the importance of communicating those skills to others. In addition, INFPs can benefit from developing realistic expectations about the job search, and from objectively looking at the logical consequences of the various decisions they make. \"\n",
      "My Real Job   It is frustrating, this waiting, this wondering about what exactly it is that I am supposed to be doing here  on this earth, in this house, with this life.  Sometimes, I cramp with shoulds;  the inside voices, huddled together, scheming over plans written in the past.  Sometimes, I burn with maybes;  lofty ideas about what a better person I might become.  I am seldom content with  the moment , unless in silence,  in meditation,  in contemplation and recognition that it is all I have.\n",
      "Being constantly screwed over by your job but still being paid well and not wanting to ruin your resume by quitting before you put in two years has to be one of the most frustrating situations in the world.\n",
      "I hope my job is like my internship all play little work :)\n",
      "I must say, you make a fine point. I capitulate in part to your theory in regard to such lame productions being partially for the purpose of appeasing one's partner, whether she be blonde or he a thug. And I also acknowledge the fact that many people watch movies and television to forget about their hard day's work. The only problem is, I am of the opinion that many people don't even think while they are  at  work. In which case, they should certainly be making up for it when they finally get home.  However, there are many of us (though growing less, it seems) who watch films for the artistry of such things as direction, cinematography, acting and set design. There is nothing I love more than a grim, morbid-looking film, a pure hit for the aesthetic-dependent. Directors like David Fincher, actors like John Malkovich, and films like Crouching Tiger, Hidden Dragon are worthy of such praise. One does not float into such films for a no-brainer, but are often woken up by the sheer talent of those involved in its production.  One of the detrimental facts of our present culture is its dependence on icons of happiness and frovility. Feeling sad? Get a hit of happy-go-lucky Coke. Feeling stupid? Go and see Legally Blonde, with the ever-so-blonde Reese Witherspoon, idolatress of the pre-pubescent generation. That should sort things out.  Because if pretty little Reese can be smart and blonde  (yet still stupid),  so can I ! The prevalence of popstars and celebreties rather than bands or musicians has infested our airwaves. I doubt Britney Spears even knows how to read music. She is an iconic vehicle for the money-making machine that is the contemporary music industry.  Therefore, in defense of my first statement, I must acknowledge, but not agree with your statement. There is nothing wrong with dumbing-down entertainment products for mass consumption after a hard day's work. But when the entire culture becomes dumbed-down, when everything you see and hear is made simple for easy digestion, it becomes crass, oversimplified and degenerative. Anxst has been buried under a snowball of pretty things and distractions. Independent thought has been smothered in bombardment from logos, images, advertisements of all kinds. We are told how to think. How to feel. How to react. And I bet pretty little Reese reacts exactly the way you expect her to. The usual tossing of the hair, poor-me syndrome followed by the notoriously easy-and-fun rise to popularity.  Yay.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: Implement dense retrieval using cosine similarity.\n",
    "# Function signature to implement:\n",
    "# def dense_search(query: str, k: int = 5) -> list[int]:\n",
    "from numpy.linalg import norm\n",
    "def dense_search(query:str, k: int = 5) -> list[int]:\n",
    "    q = model.encode([query], convert_to_numpy=True, normalize_embeddings=True).astype(\"float32\")\n",
    "    qv = q[0]\n",
    "    scores = doc_embeddings @ qv\n",
    "    k = min(k, len(scores))\n",
    "    topk_idx = np.argpartition(-scores, k-1)[:k]\n",
    "    return topk_idx[np.argsort(-scores[topk_idx])].tolist()\n",
    "\n",
    "\n",
    "indices = dense_search(\"How do people feel about their jobs?\", k=5)\n",
    "doc_ids = [ids[i] for i in indices]\n",
    "docs = [documents[k] for k in doc_ids]\n",
    "for d in docs: \n",
    "    print(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe25e527",
   "metadata": {},
   "source": [
    "\n",
    "## 4.4 – Build a Vector Search Index\n",
    "\n",
    "Build a lightweight vector index structure to enable repeated querying efficiently.\n",
    "\n",
    "- You may reuse `doc_embeddings` directly or create an index structure. Ensure the index can return top-k document indices given a query vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d959a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Initialize a vector index over `doc_embeddings`\n",
    "# Keep code minimal. The goal is to enable fast top-k retrieval for repeated queries.\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b616725",
   "metadata": {},
   "source": [
    "\n",
    "## 4.5 – RAG (Retrieval-Augmented Generation)\n",
    "\n",
    "Implement a simple RAG pipeline that:\n",
    "1) Retrieves the top-k documents for a user query using your vector index.\n",
    "2) Builds a prompt that includes the query and the retrieved document snippets.\n",
    "3) Uses a text generation model (your choice) to produce an answer grounded in the retrieved snippets.\n",
    "\n",
    "- Implement a function `rag_answer(query: str, k: int = 5) -> str`.\n",
    "- Keep the prompt simple and state clearly that the model should rely on the provided context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845e98bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Implement a minimal RAG pipeline.\n",
    "# Steps (sketch):\n",
    "# - Use `dense_search` to get top-k indices.\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922ae3d2",
   "metadata": {},
   "source": [
    "## 4.6 – Evaluation\n",
    "\n",
    "Use the following queries for your evaluation. For each query:\n",
    "\n",
    "- Run `dense_search(query, k=5)` to retrieve relevant documents.\n",
    "- Use `rag_answer(query, k=5)` to generate an answer using the top-5 retrieved documents.\n",
    "\n",
    "**Queries:**\n",
    "1. How do people deal with breakups?\n",
    "2. What do bloggers write about their daily routines?\n",
    "3. How do people feel about their jobs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6fb199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change this code\n",
    "queries = [\n",
    "    \"How do people deal with breakups?\",\n",
    "    \"What do bloggers write about their daily routines?\",\n",
    "    \"How do people feel about their jobs?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c576f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run and report your evaluation as described above.\n",
    "\n",
    "def run_batch_evaluation(queries, k=5):\n",
    "    for i, query in enumerate(queries, 1):\n",
    "        print(\"=\" * 100)\n",
    "        print(f\"Q{i}: {query}\")\n",
    "        print(\"-\" * 100)\n",
    "\n",
    "        top_k = dense_search(query, k=k)\n",
    "        print(f\"Top-{k} retrieved indices:\", top_k)\n",
    "        print(\"\\nTop retrieved snippets:\")\n",
    "        for idx in top_k:\n",
    "            snippet = documents[idx].replace(\"\\n\", \" \").strip()\n",
    "            print(f\"[{idx}] {snippet[:200]}...\\n\")\n",
    "\n",
    "        print(\"RAG answer:\\n\")\n",
    "        answer = rag_answer(query, k=k)\n",
    "        print(answer)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Run the evaluation\n",
    "run_batch_evaluation(queries, k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
