{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "298d865a",
   "metadata": {},
   "source": [
    "\n",
    "# Assignment 4: Embedding Models, Dense Retrieval, and RAG\n",
    "\n",
    "**Student names**: Vegard Aa Albretsen <br>\n",
    "**Group number**: 62 <br>\n",
    "**Date**: _We will see_\n",
    "\n",
    "## Important notes\n",
    "Please carefully read the following notes and consider them for the assignment delivery. Submissions that do not fulfill these requirements will not be assessed and should be submitted again.\n",
    "1. You may work in groups of maximum 2 students.\n",
    "2. The assignment must be delivered in ipynb format.\n",
    "3. The assignment must be typed. Handwritten assignments are not accepted.\n",
    "\n",
    "**Due date**: 26.10.2025 23:59\n",
    "\n",
    "In this assignment, you will:\n",
    "- Build a vector search index over a blog corpus using sentence embeddings\n",
    "- Implement dense retrieval (cosine similarity)\n",
    "- Use the vector index as the foundation for a simple Retrieval-Augmented Generation (RAG) chat system with evaluation on three queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf612534",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Dataset\n",
    "\n",
    "You will use the blog files, provided in the folder: \n",
    "- `blogs-sample` (in the same directory as this notebook)\n",
    "\n",
    "Use only the blog files provided in the folder below. Each file contains multiple `<post>` elements. Treat **each `<post>` as a separate document**.\n",
    "\n",
    "**The code to parse files is not provided. Implement the loading yourself in 4.1.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d681c2",
   "metadata": {},
   "source": [
    "\n",
    "## 4.1 – Load and parse blog documents\n",
    "\n",
    "Load all XML files from `blogs-sample`, extract the text of each `<post>`, and store one string per document. Keep the raw text per post as the document text.\n",
    "\n",
    "You may experience some trouble parsing all lines in the files, but this is okay.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "389dfee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 XML files under C:\\Users\\vegar\\OneDrive - NTNU\\Skule\\Fag\\Informasjonsgjenfinning\\TDT4117Assignment4\\blogs-sample\n",
      "11253.male.26.Technology.Aquarius.xml: 7 <post> tags\n",
      "11762.female.25.Student.Aries.xml: 20 <post> tags\n",
      "15365.female.34.indUnk.Cancer.xml: 844 <post> tags\n",
      "17944.female.39.indUnk.Sagittarius.xml: 128 <post> tags\n",
      "21828.male.40.Internet.Cancer.xml: 69 <post> tags\n",
      "23166.female.25.indUnk.Virgo.xml: 1 <post> tags\n",
      "23191.female.23.Advertising.Taurus.xml: 5 <post> tags\n",
      "23676.male.33.Technology.Scorpio.xml: 12 <post> tags\n",
      "24336.male.24.Technology.Leo.xml: 849 <post> tags\n",
      "26357.male.27.indUnk.Leo.xml: 41 <post> tags\n",
      "27603.male.24.Advertising.Sagittarius.xml: 52 <post> tags\n",
      "28417.female.24.Arts.Capricorn.xml: 73 <post> tags\n",
      "28451.male.27.Internet.Aquarius.xml: 13 <post> tags\n",
      "40964.female.23.RealEstate.Leo.xml: 5 <post> tags\n",
      "46465.male.25.Internet.Virgo.xml: 19 <post> tags\n",
      "47519.male.23.Communications-Media.Sagittarius.xml: 179 <post> tags\n",
      "48428.female.34.indUnk.Aquarius.xml: 5 <post> tags\n",
      "48923.female.23.Student.Virgo.xml: 128 <post> tags\n",
      "49663.male.33.indUnk.Taurus.xml: 1252 <post> tags\n",
      "61176.male.33.Technology.Capricorn.xml: 3 <post> tags\n",
      "7596.male.26.Internet.Scorpio.xml: 14 <post> tags\n",
      "8173.male.42.indUnk.Capricorn.xml: 1007 <post> tags\n",
      "8349.male.24.Consulting.Cancer.xml: 70 <post> tags\n",
      "9289.male.23.Marketing.Taurus.xml: 89 <post> tags\n",
      "9470.male.25.Communications-Media.Aries.xml: 360 <post> tags\n",
      "Total posts: 5245\n",
      "11253.male.26.Technology.Aquarius.xml#1 => About to go t bed late (again) got sucked into (another) late night film. Tonight was  urlLink Maybe Baby . It was reall\n",
      "11253.male.26.Technology.Aquarius.xml#2 => My Dad has always wanted to go to  urlLink America . I have been several times, for holidays, to see friends or for work\n",
      "11253.male.26.Technology.Aquarius.xml#3 => ...is a guy painting a blue wall blue.\n",
      "11253.male.26.Technology.Aquarius.xml#4 => Can't the  urlLink weather  just sort itself out. I'm sure we'd already had 2 heat waves by this point last year. I look\n",
      "11253.male.26.Technology.Aquarius.xml#5 => At last back to a normal company where it expected that you go to the pub at lunch on Fridays. Plus they have free break\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "folder = Path(\"blogs-sample\").resolve()\n",
    "assert folder.is_dir(), f\"Folder not found: {folder}\"\n",
    "\n",
    "documents = {}\n",
    "files = [p for p in folder.rglob(\"*.xml\")]\n",
    "\n",
    "print(f\"Found {len(files)} XML files under {folder}\")\n",
    "\n",
    "for f in files:\n",
    "    data = f.read_bytes()\n",
    "    soup = BeautifulSoup(data, \"xml\")\n",
    "\n",
    "    # strip namespace prefixes like ns:post -> post\n",
    "    for t in soup.find_all(True):\n",
    "        if \":\" in t.name:\n",
    "            t.name = t.name.split(\":\", 1)[1]\n",
    "\n",
    "    # posts directly anywhere under Blog/date/post/date/post...\n",
    "    posts = soup.find_all(\"post\")\n",
    "    print(f\"{f.name}: {len(posts)} <post> tags\")\n",
    "\n",
    "    for i, p in enumerate(posts, 1):\n",
    "        documents[f\"{f.name}#{i}\"] = p.get_text(strip=True)\n",
    "\n",
    "print(f\"Total posts: {len(documents)}\")\n",
    "# show a few\n",
    "for k, v in list(documents.items())[:5]:\n",
    "    print(k, \"=>\", v[:120])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eda412",
   "metadata": {},
   "source": [
    "\n",
    "## 4.2 – Embedding Models\n",
    "\n",
    "Select and load a sentence embedding model (e.g., `sentence-transformers/all-MiniLM-L6-v2`) and compute embeddings for all documents.\n",
    "\n",
    "- Store document embeddings in a variable named `doc_embeddings`.\n",
    "- Ensure that the same model will be used for query encoding later.\n",
    "\n",
    "**Report**:\n",
    "- The embedding matrix shape \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "146a6c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vegar\\OneDrive - NTNU\\Skule\\Fag\\Informasjonsgjenfinning\\TDT4117Assignment4\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\vegar\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5245\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: Load a sentence embedding model and encode all documents into `doc_embeddings`.\n",
    "# You may use `sentence-transformers`. Report the embedding matrix shape.\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "ids, texts = zip(*documents.items())  # ids: tuple[str], texts: tuple[str]\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")  # 384-dim\n",
    "emb = model.encode(\n",
    "    list(texts),\n",
    "    batch_size=128,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True,   # cosine via inner product\n",
    ")\n",
    "emb = emb.astype(\"float32\")      # FAISS wants float32\n",
    "# Your code here\n",
    "\n",
    "d = emb.shape[1]\n",
    "index = faiss.IndexFlatIP(d)     # exact search, inner product\n",
    "index.add(emb)\n",
    "print(index.ntotal)     \n",
    "\n",
    "faiss.write_index(index, \"index.faiss\")\n",
    "np.save(\"ids.npy\", np.array(ids, dtype=object))  # keeps ordering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6defe752",
   "metadata": {},
   "source": [
    "\n",
    "## 4.3 – Dense Retrieval\n",
    "\n",
    "Implement a cosine similarity search over `doc_embeddings` for a given query.\n",
    "\n",
    "- Write a function `dense_search(query: str, k: int = 5) -> list[int]` that returns the indices of the top-k documents.\n",
    "- Use the same embedding model to encode the query.\n",
    "- Use cosine similarity for ranking.\n",
    "\n",
    "**Report**:\n",
    "- Results for the provided query showing the indices of the top results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35dd7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Implement dense retrieval using cosine similarity.\n",
    "# Function signature to implement:\n",
    "# def dense_search(query: str, k: int = 5) -> list[int]:\n",
    "\n",
    "# Your code here\n",
    "\n",
    "#Report\n",
    "print(dense_search(\"How do people feel about their jobs?\", k=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe25e527",
   "metadata": {},
   "source": [
    "\n",
    "## 4.4 – Build a Vector Search Index\n",
    "\n",
    "Build a lightweight vector index structure to enable repeated querying efficiently.\n",
    "\n",
    "- You may reuse `doc_embeddings` directly or create an index structure. Ensure the index can return top-k document indices given a query vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d959a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Initialize a vector index over `doc_embeddings`\n",
    "# Keep code minimal. The goal is to enable fast top-k retrieval for repeated queries.\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b616725",
   "metadata": {},
   "source": [
    "\n",
    "## 4.5 – RAG (Retrieval-Augmented Generation)\n",
    "\n",
    "Implement a simple RAG pipeline that:\n",
    "1) Retrieves the top-k documents for a user query using your vector index.\n",
    "2) Builds a prompt that includes the query and the retrieved document snippets.\n",
    "3) Uses a text generation model (your choice) to produce an answer grounded in the retrieved snippets.\n",
    "\n",
    "- Implement a function `rag_answer(query: str, k: int = 5) -> str`.\n",
    "- Keep the prompt simple and state clearly that the model should rely on the provided context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845e98bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Implement a minimal RAG pipeline.\n",
    "# Steps (sketch):\n",
    "# - Use `dense_search` to get top-k indices.\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922ae3d2",
   "metadata": {},
   "source": [
    "## 4.6 – Evaluation\n",
    "\n",
    "Use the following queries for your evaluation. For each query:\n",
    "\n",
    "- Run `dense_search(query, k=5)` to retrieve relevant documents.\n",
    "- Use `rag_answer(query, k=5)` to generate an answer using the top-5 retrieved documents.\n",
    "\n",
    "**Queries:**\n",
    "1. How do people deal with breakups?\n",
    "2. What do bloggers write about their daily routines?\n",
    "3. How do people feel about their jobs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6fb199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change this code\n",
    "queries = [\n",
    "    \"How do people deal with breakups?\",\n",
    "    \"What do bloggers write about their daily routines?\",\n",
    "    \"How do people feel about their jobs?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c576f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run and report your evaluation as described above.\n",
    "\n",
    "def run_batch_evaluation(queries, k=5):\n",
    "    for i, query in enumerate(queries, 1):\n",
    "        print(\"=\" * 100)\n",
    "        print(f\"Q{i}: {query}\")\n",
    "        print(\"-\" * 100)\n",
    "\n",
    "        top_k = dense_search(query, k=k)\n",
    "        print(f\"Top-{k} retrieved indices:\", top_k)\n",
    "        print(\"\\nTop retrieved snippets:\")\n",
    "        for idx in top_k:\n",
    "            snippet = documents[idx].replace(\"\\n\", \" \").strip()\n",
    "            print(f\"[{idx}] {snippet[:200]}...\\n\")\n",
    "\n",
    "        print(\"RAG answer:\\n\")\n",
    "        answer = rag_answer(query, k=k)\n",
    "        print(answer)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Run the evaluation\n",
    "run_batch_evaluation(queries, k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
